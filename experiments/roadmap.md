# ロードマップ（nuScenes → 背景GS）

## Phase 0: 環境・パイプライン検証（完了）

### 使うデータ

* nuScenes v1.0-mini
* CAM_FRONT
* ego_pose / calibrated_sensor（与え姿勢）

### 使うシーンの特徴

* 何でもOK（まず動くこと優先）
* ただし失敗を避けるなら低速・停止が多いほど良い

### 達成したいこと

* **COLMAPなし**で、与え姿勢から **3DGSが学習できる**
* **レンダが出る**（破綻してないカメラパス再現）

### やること

* CAM_FRONT抽出 → world↔cam行列生成 → Nerfstudio形式 → splatfacto学習 → viewer確認

---

## Phase 1: “背景だけ学習”を成立させる（最優先）

### 使うデータ

* nuScenes（mini → trainvalへ拡張可）
* CAM_FRONT
* **sample_annotation（3D bbox）** ← 追加DL不要

### 使うシーンの特徴（成功率が高い）

* **低速・停止が多い**
* 動体が写ってもよいが、**画面を埋め尽くさない**
* 直線高速より、信号待ち・渋滞・右左折が混ざる方が良い

### 達成したいこと

* 車・歩行者などの **動体が背景に焼き付かない**
* 近景〜中景の背景が安定する（放射状ノイズが減る）

### やること

1. **3D bboxをCAM_FRONTへ投影**して2Dマスク生成

   * 対象：`vehicle.* / human.* / cycle.*`（必要なら `movable_object.*`）
   * マスクは**大きめ**（dilation推奨）
2. 学習時に **マスク領域をlossから除外**（黒塗りより安定）
3. まずは **30〜80枚**・低速区間で再学習し、改善を確認

---

## Phase 2: マスク精度を上げて“残像”をさらに減らす

### 使うデータ

* **nuScenes-lidarseg または nuScenes-panoptic**（追加パック）

  * LiDAR keyframe 点群に semantic（+panopticはinstanceも）
* CAM_FRONT（引き続き）
* ego_pose / calibrated_sensor

### 使うシーンの特徴

* Phase 1と同じ（低速優先）
* 動体が多いシーンでも対応力を上げたい段階

### 達成したいこと

* bbox投影で残る「輪郭の漏れ」「bbox外の飛び出し」を減らす
* 背景に残る“ゴースト”を目立たなくする

### やること

1. lidarseg/panopticで **vehicle/human/cycle のLiDAR点を除去**
2. 残った **静的点群**をカメラに投影して **精密マスク**を作る
3. bboxマスクと論理和を取って **リークを潰す**（dilation込み）
4. 再学習して比較（PSNRより見た目でOK）

---

## Phase 3: 背景の形を安定化（Plan B：幾何拘束）

### 使うデータ

* CAM_FRONT
* ego_pose / calibrated_sensor
* LiDAR（sweeps or keyframe）
* lidarseg/panoptic（あると静的深度が作りやすい）

### 使うシーンの特徴

* **道路スケールが大きい（遠景が多い）**シーンで効果が大きい
* 直線区間や遠景が抜ける区間

### 達成したいこと

* 遠景の漂い、地面のうねり、スケール不安定を抑える
* “背景の形”が安定し、再利用できる土台になる

### やること

1. 静的LiDAR点（動体除去済み）→ CAM_FRONTへ投影
2. **スパース深度**を生成（欠損はOK）
3. 深度loss/幾何正則化を追加（Nerfstudio派生 or 自前改造）
4. 遠景の安定度で評価（見た目＋軌跡レンダ）

---

## Phase 4: マルチカメラ化（最終形へ）

### 使うデータ

* CAM_FRONT + CAM_FRONT_LEFT + CAM_FRONT_RIGHT（まず3台）
* ego_pose / calibrated_sensor（各cameraのsample_dataごと）
* （必要なら）lidarseg/panoptic, LiDAR拘束

### 使うシーンの特徴

* カメラ間で見える共通領域が多いシーン（交差点/市街地は強い）
* 露出差が大きいので、極端な逆光シーンは後回し

### 達成したいこと

* 横方向の構造（建物側面、路肩、歩道）を安定化
* 将来的な「周囲車両を破綻なく見せる」土台になる

### やること

1. まず3台（Front/Front-Left/Front-Right）だけ追加
2. 露出差対策（軽い色正規化）を必要に応じて導入
3. マスク戦略はPhase 1/2のまま適用
4. 破綻なく背景が立つまで反復

---

## Phase 5: “穴埋め”と再利用性の向上（仕上げ）

### 使うデータ

* 同一路線の別走行（あなたの強み：反復走行データ）
* 既存背景GS（固定）
* 追加フレーム（穴が見える瞬間）

### 使うシーンの特徴

* “穴が見える”視点が含まれる（別走行・別レーンなどが効く）

### 達成したいこと

* 動体を消した結果できる欠損（穴）を自然に埋める
* 背景GSを「シナリオテスト用アセット」として安定運用できる

### やること

1. 背景GSを固定し、追加フレームで欠損を埋める
2. 必要なら2D inpaintで補助（軽い仕上げとして）
3. 評価：任意視点レンダで破綻がないこと

---

# 重要な設計原則（このロードマップの背骨）

* **2Hzは厳しいが、低速区間＋動体マスクで十分戦える**
* 歪みは基本気にしない（nuScenes画像は補正済み）
* 改善の優先順位は
  **動体マスク → 幾何安定（LiDAR）→ マルチカメラ → 高周期**
* “まずレンダが出る”を守る（あなたは既に達成）

---

必要なら次に、Phase 1の **実装タスクをそのままTODOに分解**します（所要時間付き）。
具体的には「3D bbox投影マスク生成」「Nerfstudioでloss除外」「評価用レンダ比較（Before/After）」を1セットにして出せます。
